{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from net2brain.utils.download_datasets import DatasetNSD_872\n",
    "from net2brain.feature_extraction import FeatureExtractor\n",
    "from net2brain.evaluations.ridge_regression import Ridge_Encoding\n",
    "from net2brain.evaluations.plotting import Plotting\n",
    "import os\n",
    "\n",
    "State = namedtuple('State', ['layer_type', 'layer_depth', 'num_filters', 'kernel_size', 'fc_count'])\n",
    "Action = namedtuple('Action', ['layer_type', 'num_filters', 'kernel_size', 'skip_connection'])\n",
    "\n",
    "class CNNArchitectureSampler:\n",
    "    def __init__(self, max_depth=20, input_shape=(3, 224, 224), roi_path=None, stimuli_path=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.input_shape = input_shape\n",
    "        self.layer_types = ['conv', 'pool', 'fc', 'output']\n",
    "        self.num_filters_options = [16, 32, 64, 128, 256]\n",
    "        self.kernel_sizes = [1, 3, 5, 7]\n",
    "        self.skip_connection_options = [True, False]\n",
    "        self.roi_path = roi_path\n",
    "        self.stimuli_path = stimuli_path\n",
    "\n",
    "        # Add the input shape's channel count to num_filters_options if it's not already there\n",
    "        if input_shape[0] not in self.num_filters_options:\n",
    "            self.num_filters_options = [input_shape[0]] + self.num_filters_options\n",
    "\n",
    "        self.state_space = len(self.layer_types) * max_depth * len(self.num_filters_options) * len(self.kernel_sizes) * 3  # 3 for fc_count (0, 1, 2)\n",
    "        self.action_space = (len(self.layer_types) * \n",
    "                             len(self.num_filters_options) * \n",
    "                             len(self.kernel_sizes) * \n",
    "                             len(self.skip_connection_options))\n",
    "\n",
    "        self.q_table = np.zeros((self.state_space, self.action_space))\n",
    "        self.epsilon = 1.0\n",
    "        self.alpha = 0.1\n",
    "        self.gamma = 0.9\n",
    "        self.total_models_sampled = 0\n",
    "\n",
    "    def update_epsilon(self):\n",
    "        if self.total_models_sampled <= 1500:\n",
    "            self.epsilon = 1.0\n",
    "        else:\n",
    "            self.epsilon = max(0.1, 1.0 - (self.total_models_sampled - 1500) // 100 * 0.1)\n",
    "\n",
    "    def state_to_index(self, state):\n",
    "        layer_type_idx = self.layer_types.index(state.layer_type) if state.layer_type != -1 else 0\n",
    "        num_filters_idx = self.num_filters_options.index(state.num_filters) if state.num_filters in self.num_filters_options else 0\n",
    "        kernel_size_idx = self.kernel_sizes.index(state.kernel_size) if state.kernel_size in self.kernel_sizes else 0\n",
    "        return (layer_type_idx * self.max_depth * len(self.num_filters_options) * len(self.kernel_sizes) * 3 +\n",
    "                state.layer_depth * len(self.num_filters_options) * len(self.kernel_sizes) * 3 +\n",
    "                num_filters_idx * len(self.kernel_sizes) * 3 +\n",
    "                kernel_size_idx * 3 +\n",
    "                state.fc_count)\n",
    "\n",
    "    def action_to_index(self, action):\n",
    "        layer_type_idx = self.layer_types.index(action.layer_type)\n",
    "        num_filters_idx = self.num_filters_options.index(action.num_filters) if action.layer_type != 'pool' else 0\n",
    "        kernel_size_idx = self.kernel_sizes.index(action.kernel_size) if action.layer_type in ['conv', 'pool'] else 0\n",
    "        skip_idx = int(action.skip_connection)\n",
    "        return (layer_type_idx * len(self.num_filters_options) * len(self.kernel_sizes) * 2 +\n",
    "                num_filters_idx * len(self.kernel_sizes) * 2 +\n",
    "                kernel_size_idx * 2 +\n",
    "                skip_idx)\n",
    "\n",
    "    def index_to_action(self, index):\n",
    "        skip_idx = index % 2\n",
    "        index //= 2\n",
    "        kernel_idx = index % len(self.kernel_sizes)\n",
    "        index //= len(self.kernel_sizes)\n",
    "        num_filters_idx = index % len(self.num_filters_options)\n",
    "        index //= len(self.num_filters_options)\n",
    "        layer_type_idx = index\n",
    "\n",
    "        layer_type = self.layer_types[layer_type_idx]\n",
    "        num_filters = self.num_filters_options[num_filters_idx] if layer_type != 'pool' else 0\n",
    "        kernel_size = self.kernel_sizes[kernel_idx] if layer_type in ['conv', 'pool'] else 0\n",
    "\n",
    "        return Action(\n",
    "            layer_type=layer_type,\n",
    "            num_filters=num_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            skip_connection=bool(skip_idx)\n",
    "        )\n",
    "\n",
    "    def sample_action(self, state):\n",
    "        self.update_epsilon()\n",
    "        state_idx = self.state_to_index(state)\n",
    "        if random.random() < self.epsilon:\n",
    "            return self.index_to_action(random.randint(0, self.action_space - 1))\n",
    "        else:\n",
    "            action_idx = np.argmax(self.q_table[state_idx])\n",
    "            return self.index_to_action(action_idx)\n",
    "\n",
    "    def is_valid_action(self, state, action):\n",
    "        if action.layer_type == 'output':\n",
    "            return True\n",
    "        if state.layer_depth >= self.max_depth - 1:\n",
    "            return action.layer_type == 'output'\n",
    "        if state.layer_type == 'pool' and action.layer_type == 'pool':\n",
    "            return False\n",
    "        if action.layer_type == 'fc':\n",
    "            if state.fc_count >= 2:\n",
    "                return False\n",
    "            if state.layer_type == 'fc' and action.num_filters > state.num_filters:\n",
    "                return False\n",
    "        if state.layer_type in ['conv', 'pool'] and action.layer_type == 'fc':\n",
    "            current_size = self.input_shape[1] // (2 ** state.layer_depth)\n",
    "            if current_size > 8:\n",
    "                return False\n",
    "        if state.layer_type == 'fc' and action.layer_type in ['conv', 'pool']:\n",
    "            return False  # Prevent conv or pool layers after fc layers\n",
    "        if action.skip_connection and (state.layer_type == 'fc' or action.layer_type == 'fc'):\n",
    "            return False  # Prevent skip connections to or from FC layers\n",
    "        return True\n",
    "    \n",
    "    def architecture_to_torch_model(self, architecture, skip_connections):\n",
    "        class CNNModel(nn.Module):\n",
    "            def __init__(self, arch, skips, input_shape):\n",
    "                super(CNNModel, self).__init__()\n",
    "                self.layers = nn.ModuleList()\n",
    "                self.skips = []\n",
    "                \n",
    "                in_channels = input_shape[0]\n",
    "                current_size = input_shape[1]\n",
    "                fc_input_size = 0\n",
    "                is_flattened = False\n",
    "                \n",
    "                for i, (layer_type, num_filters, kernel_size) in enumerate(arch):\n",
    "                    if layer_type == 'conv':\n",
    "                        if is_flattened:\n",
    "                            break  # Stop adding layers if we've already flattened\n",
    "                        self.layers.append(nn.Conv2d(in_channels, num_filters, kernel_size, padding=kernel_size//2))\n",
    "                        self.layers.append(nn.ReLU())\n",
    "                        in_channels = num_filters\n",
    "                    elif layer_type == 'pool':\n",
    "                        if is_flattened:\n",
    "                            break  # Stop adding layers if we've already flattened\n",
    "                        self.layers.append(nn.MaxPool2d(2))\n",
    "                        current_size //= 2\n",
    "                    elif layer_type == 'fc':\n",
    "                        if not is_flattened:\n",
    "                            fc_input_size = in_channels * current_size * current_size\n",
    "                            self.layers.append(nn.Flatten())\n",
    "                            is_flattened = True\n",
    "                        self.layers.append(nn.Linear(fc_input_size, num_filters))\n",
    "                        self.layers.append(nn.ReLU())\n",
    "                        fc_input_size = num_filters\n",
    "                \n",
    "                # Remove the last ReLU layer to allow for proper output scaling\n",
    "                if isinstance(self.layers[-1], nn.ReLU):\n",
    "                    self.layers = self.layers[:-1]\n",
    "                \n",
    "                # Filter valid skip connections\n",
    "                for start, end in skips:\n",
    "                    if start < end and start < len(self.layers) and end < len(self.layers):\n",
    "                        self.skips.append((start, end))\n",
    "            \n",
    "            def forward(self, x):\n",
    "                skip_outputs = {}\n",
    "                for i, layer in enumerate(self.layers):\n",
    "                    if i in [s[0] for s in self.skips]:\n",
    "                        skip_outputs[i] = x\n",
    "                    if i in [s[1] for s in self.skips]:\n",
    "                        skip_source = [s[0] for s in self.skips if s[1] == i]\n",
    "                        if skip_source and skip_source[0] in skip_outputs:\n",
    "                            skip_x = skip_outputs[skip_source[0]]\n",
    "                            if x.shape != skip_x.shape:\n",
    "                                print(f\"Shape mismatch at layer {i}: x: {x.shape}, skip: {skip_x.shape}\")\n",
    "                                # Skip this connection if shapes don't match\n",
    "                                continue\n",
    "                            x = x + skip_x\n",
    "                    x = layer(x)\n",
    "                return x\n",
    "\n",
    "        return CNNModel(architecture, skip_connections, self.input_shape)\n",
    "\n",
    "    def sample_architecture(self):\n",
    "        architecture = []\n",
    "        skip_connections = []\n",
    "        state = State(layer_type=-1, layer_depth=0, num_filters=self.input_shape[0], kernel_size=3, fc_count=0)\n",
    "\n",
    "        while True:\n",
    "            valid_action = False\n",
    "            while not valid_action:\n",
    "                action = self.sample_action(state)\n",
    "                valid_action = self.is_valid_action(state, action)\n",
    "\n",
    "            if action.layer_type == 'output' or state.layer_depth >= self.max_depth - 1:\n",
    "                break\n",
    "\n",
    "            if action.layer_type == 'conv':\n",
    "                # Ensure the number of filters is valid\n",
    "                action = action._replace(num_filters=max(action.num_filters, state.num_filters))\n",
    "\n",
    "            architecture.append((action.layer_type, action.num_filters, action.kernel_size))\n",
    "            \n",
    "            # Sample skip connections\n",
    "            if len(architecture) > 1 and action.skip_connection:\n",
    "                possible_skip_starts = [i for i, (layer_type, _, _) in enumerate(architecture[:-1])\n",
    "                                        if layer_type in ['conv', 'pool']]\n",
    "                if possible_skip_starts:\n",
    "                    skip_start = random.choice(possible_skip_starts)\n",
    "                    skip_connections.append((skip_start, len(architecture) - 1))\n",
    "            \n",
    "            new_fc_count = state.fc_count + 1 if action.layer_type == 'fc' else state.fc_count\n",
    "            state = State(\n",
    "                layer_type=action.layer_type,\n",
    "                layer_depth=state.layer_depth + 1,\n",
    "                num_filters=action.num_filters,\n",
    "                kernel_size=action.kernel_size,\n",
    "                fc_count=new_fc_count\n",
    "            )\n",
    "\n",
    "        return architecture, skip_connections\n",
    "\n",
    "    def architecture_to_torch_model(self, architecture, skip_connections):\n",
    "        class CNNModel(nn.Module):\n",
    "            def __init__(self, arch, skips, input_shape):\n",
    "                super(CNNModel, self).__init__()\n",
    "                self.layers = nn.ModuleList()\n",
    "                self.skips = []\n",
    "                \n",
    "                in_channels = input_shape[0]\n",
    "                current_size = input_shape[1]\n",
    "                fc_input_size = 0\n",
    "                is_flattened = False\n",
    "                \n",
    "                if not arch:  # If the architecture is empty, add a default layer\n",
    "                    self.layers.append(nn.Conv2d(in_channels, 64, 3, padding=1))\n",
    "                    self.layers.append(nn.ReLU())\n",
    "                    self.layers.append(nn.Flatten())\n",
    "                    self.layers.append(nn.Linear(64 * current_size * current_size, 10))\n",
    "                else:\n",
    "                    for i, (layer_type, num_filters, kernel_size) in enumerate(arch):\n",
    "                        if layer_type == 'conv':\n",
    "                            if is_flattened:\n",
    "                                break  # Stop adding layers if we've already flattened\n",
    "                            self.layers.append(nn.Conv2d(in_channels, num_filters, kernel_size, padding=kernel_size//2))\n",
    "                            self.layers.append(nn.ReLU())\n",
    "                            in_channels = num_filters\n",
    "                        elif layer_type == 'pool':\n",
    "                            if is_flattened:\n",
    "                                break  # Stop adding layers if we've already flattened\n",
    "                            self.layers.append(nn.MaxPool2d(2))\n",
    "                            current_size //= 2\n",
    "                        elif layer_type == 'fc':\n",
    "                            if not is_flattened:\n",
    "                                fc_input_size = in_channels * current_size * current_size\n",
    "                                self.layers.append(nn.Flatten())\n",
    "                                is_flattened = True\n",
    "                            self.layers.append(nn.Linear(fc_input_size, num_filters))\n",
    "                            self.layers.append(nn.ReLU())\n",
    "                            fc_input_size = num_filters\n",
    "                            in_channels = num_filters  # Update in_channels for potential future layers\n",
    "                    \n",
    "                    # If we haven't added any FC layers, add a default output layer\n",
    "                    if not is_flattened:\n",
    "                        self.layers.append(nn.Flatten())\n",
    "                        self.layers.append(nn.Linear(in_channels * current_size * current_size, 10))\n",
    "                \n",
    "                # Remove the last ReLU layer to allow for proper output scaling\n",
    "                if isinstance(self.layers[-1], nn.ReLU):\n",
    "                    self.layers = self.layers[:-1]\n",
    "                \n",
    "                # Filter valid skip connections\n",
    "                for start, end in skips:\n",
    "                    if start < end and start < len(self.layers) and end < len(self.layers):\n",
    "                        self.skips.append((start, end))\n",
    "            \n",
    "            def forward(self, x):\n",
    "                skip_outputs = {}\n",
    "                for i, layer in enumerate(self.layers):\n",
    "                    if i in [s[0] for s in self.skips]:\n",
    "                        skip_outputs[i] = x\n",
    "                    if i in [s[1] for s in self.skips]:\n",
    "                        skip_source = [s[0] for s in self.skips if s[1] == i]\n",
    "                        if skip_source and skip_source[0] in skip_outputs:\n",
    "                            skip_x = skip_outputs[skip_source[0]]\n",
    "                            if x.shape != skip_x.shape:\n",
    "                                # Adjust the skip connection to match the current tensor shape\n",
    "                                skip_x = self.adjust_skip_connection(skip_x, x.shape)\n",
    "                            x = x + skip_x\n",
    "                    x = layer(x)\n",
    "                return x\n",
    "\n",
    "            def adjust_skip_connection(self, skip_x, target_shape):\n",
    "                # Adjust the number of channels and spatial dimensions if needed\n",
    "                if skip_x.shape[1] != target_shape[1]:\n",
    "                    # Adjust number of channels\n",
    "                    skip_x = nn.functional.conv2d(skip_x, torch.randn(target_shape[1], skip_x.shape[1], 1, 1))\n",
    "                if skip_x.shape[2:] != target_shape[2:]:\n",
    "                    # Adjust spatial dimensions\n",
    "                    skip_x = nn.functional.interpolate(skip_x, size=target_shape[2:])\n",
    "                return skip_x\n",
    "\n",
    "        return CNNModel(architecture, skip_connections, self.input_shape)\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        # Encourage wide and deep architectures\n",
    "        fx = FeatureExtractor(model=model, device='cpu')\n",
    "\n",
    "        # generate random number between 0 and 10000\n",
    "        random.seed(42)\n",
    "        random_number = random.randint(0, 10000)\n",
    "\n",
    "        fx.extract(data_path=self.stimuli_path, save_path=f\"{random_number}_res\", consolidate_per_layer=False)\n",
    "\n",
    "        results_dataframe = Ridge_Encoding(\n",
    "            f\"{random_number}_res\",\n",
    "            self.roi_path,\n",
    "            f\"{random_number}_model\",\n",
    "            n_folds=3,\n",
    "            trn_tst_split=0.8,\n",
    "            n_components=100,\n",
    "            batch_size=64,\n",
    "            return_correlations=True,\n",
    "            save_path=\"results\",\n",
    "            alpha=1.0,\n",
    "        )\n",
    "\n",
    "        layer = results_dataframe.Layer.unique()[-1]\n",
    "        last_layer_df = results_dataframe[results_dataframe.Layer == layer]\n",
    "       \n",
    "        # remove the results file after evaluation\n",
    "        os.remove(f\"{random_number}_res\")\n",
    "\n",
    "        return last_layer_df.R.mean()\n",
    "\n",
    "    def train(self, num_episodes=10, models_per_episode=100):\n",
    "        for _ in range(num_episodes):\n",
    "            architectures = []\n",
    "            models = []\n",
    "            rewards = []\n",
    "\n",
    "            # Sample 100 architectures and create PyTorch models\n",
    "            for _ in range(models_per_episode):\n",
    "                arch, skips = self.sample_architecture()\n",
    "                architectures.append((arch, skips))\n",
    "                model = self.architecture_to_torch_model(arch, skips)\n",
    "                models.append(model)\n",
    "                rewards.append(self.evaluate_model(model))\n",
    "                self.total_models_sampled += 1\n",
    "\n",
    "            # Update Q-values for each architecture\n",
    "            for (architecture, skip_connections), reward in zip(architectures, rewards):\n",
    "                for i in range(len(architecture) - 1):\n",
    "                    state = State(layer_type=architecture[i][0], layer_depth=i, \n",
    "                                  num_filters=architecture[i][1], kernel_size=architecture[i][2],\n",
    "                                  fc_count=sum(1 for layer in architecture[:i+1] if layer[0] == 'fc'))\n",
    "                    next_state = State(layer_type=architecture[i+1][0], layer_depth=i+1,\n",
    "                                       num_filters=architecture[i+1][1], kernel_size=architecture[i+1][2],\n",
    "                                       fc_count=sum(1 for layer in architecture[:i+2] if layer[0] == 'fc'))\n",
    "                    action = Action(\n",
    "                        layer_type=architecture[i][0],\n",
    "                        num_filters=architecture[i][1],\n",
    "                        kernel_size=architecture[i][2],\n",
    "                        skip_connection=any(s[0] == i or s[1] == i for s in skip_connections)\n",
    "                    )\n",
    "                    \n",
    "                    self.update_q_value(state, action, next_state, reward)\n",
    "\n",
    "            print(f\"Episode completed. Best reward: {max(rewards):.4f}, Epsilon: {self.epsilon:.2f}\")\n",
    "\n",
    "    def update_q_value(self, state, action, next_state, reward):\n",
    "        state_idx = self.state_to_index(state)\n",
    "        action_idx = self.action_to_index(action)\n",
    "        next_state_idx = self.state_to_index(next_state)\n",
    "\n",
    "        current_q = self.q_table[state_idx, action_idx]\n",
    "        next_max_q = np.max(self.q_table[next_state_idx])\n",
    "        new_q = current_q + self.alpha * (reward + self.gamma * next_max_q - current_q)\n",
    "        self.q_table[state_idx, action_idx] = new_q\n",
    "\n",
    "    @ray.remote\n",
    "    def sample_and_evaluate(self):\n",
    "        architecture, skip_connections = self.sample_architecture()\n",
    "        model = self.architecture_to_torch_model(architecture, skip_connections)\n",
    "        reward = self.evaluate_model(model)\n",
    "        return architecture, skip_connections, reward\n",
    "\n",
    "    def train_parallel(self, num_episodes=10, models_per_episode=100):\n",
    "        for episode in range(num_episodes):\n",
    "            # Sample and evaluate models in parallel\n",
    "            futures = [self.sample_and_evaluate.remote(self) for _ in range(models_per_episode)]\n",
    "            results = ray.get(futures)\n",
    "\n",
    "            architectures, skip_connections_list, rewards = zip(*results)\n",
    "\n",
    "            # Update Q-values for each architecture\n",
    "            for architecture, skip_connections, reward in zip(architectures, skip_connections_list, rewards):\n",
    "                for i in range(len(architecture) - 1):\n",
    "                    state = State(layer_type=architecture[i][0], layer_depth=i, \n",
    "                                  num_filters=architecture[i][1], kernel_size=architecture[i][2],\n",
    "                                  fc_count=sum(1 for layer in architecture[:i+1] if layer[0] == 'fc'))\n",
    "                    next_state = State(layer_type=architecture[i+1][0], layer_depth=i+1,\n",
    "                                       num_filters=architecture[i+1][1], kernel_size=architecture[i+1][2],\n",
    "                                       fc_count=sum(1 for layer in architecture[:i+2] if layer[0] == 'fc'))\n",
    "                    action = Action(\n",
    "                        layer_type=architecture[i][0],\n",
    "                        num_filters=architecture[i][1],\n",
    "                        kernel_size=architecture[i][2],\n",
    "                        skip_connection=any(s[0] == i or s[1] == i for s in skip_connections)\n",
    "                    )\n",
    "                    \n",
    "                    self.update_q_value(state, action, next_state, reward)\n",
    "\n",
    "            self.total_models_sampled += models_per_episode\n",
    "            print(f\"Episode {episode + 1} completed. Best reward: {max(rewards):.4f}, Epsilon: {self.epsilon:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "sampler = CNNArchitectureSampler(max_depth=20, input_shape=(3, 32, 32))\n",
    "\n",
    "# Train the sampler\n",
    "sampler.train(num_episodes=1, models_per_episode=100)\n",
    "\n",
    "# Sample and evaluate a single model after training\n",
    "architecture, skip_connections = sampler.sample_architecture()\n",
    "model = sampler.architecture_to_torch_model(architecture, skip_connections)\n",
    "reward = sampler.evaluate_model(model)\n",
    "\n",
    "print(\"Sampled architecture:\", architecture)\n",
    "print(\"Skip connections:\", skip_connections)\n",
    "print(\"Model evaluation:\", reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture, skip_connections = sampler.sample_architecture()\n",
    "model = sampler.architecture_to_torch_model(architecture, skip_connections)\n",
    "reward = sampler.evaluate_model(model)\n",
    "\n",
    "print(\"Sampled architecture:\", architecture, \"Skip Connections:\", skip_connections)\n",
    "res = model(torch.randn(1, 3, 32, 32))\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
